{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf9d8689",
   "metadata": {},
   "source": [
    "# Markov Decision Processes\n",
    "\n",
    "This tutorial is motivated by the awesome lecture of Dorsa Sadigh and Percy Liang [Stanford CS221: Artificial Intelligence: Principles and Techniques | Autumn 2019](\n",
    "https://www.youtube.com/playlist?list=PLoROMvodv4rO1NB9TD4iUZ3qghGEGtqNX)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bfb30b",
   "metadata": {},
   "source": [
    "\n",
    "1. $S:$ The set of states\n",
    "2. $A(s)$:Possible actions from state\n",
    "3. $T(s,a,s'):$\n",
    "4. $R(s,a,s')$\n",
    "5. $IsEnd(s)$\n",
    "6. $0\\ge \\gamma \\ge 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4a94ef",
   "metadata": {},
   "source": [
    "## Motivating Example :Transportation Problem\n",
    "**Problem Setup:**\n",
    "1. Street with blocks numbered 1 to n\n",
    "2. Walking from s to s+1 takes 1 minute.\n",
    "3. Taking a magic tram from s to 2s takes 2 minutes.\n",
    "4. __Traim fails with probability .5__\n",
    "\n",
    "=> How to go  from 1 to n in the least time ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdfc4f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['walk', 'tram']\n",
      "['walk']\n",
      "[(4, 1.0, -1.0)]\n",
      "[(8, 0.5, -2.0), (4, 0.5, -2.0)]\n"
     ]
    }
   ],
   "source": [
    "class TransportationMDP:\n",
    "    def __init__(self, N,fail_prob=.5):\n",
    "        self.N = N\n",
    "        self.fail_prob=fail_prob\n",
    "    def startState(self)-> int:\n",
    "        return 1\n",
    "    def isEnd(self, state)-> bool:\n",
    "        return state == self.N\n",
    "    def actions(self,state):\n",
    "        result = []\n",
    "        if state +1 <= self.N:\n",
    "            result.append('walk')\n",
    "        if state*2 <= self.N:\n",
    "            result.append('tram')\n",
    "        return result    \n",
    "    def succProbReward(self, state,action):\n",
    "        result = []\n",
    "        if action =='walk':\n",
    "            result.append((state+1, 1.,-1.))\n",
    "        elif action =='tram':\n",
    "            result.append((state*2,1-self.fail_prob ,-2.))\n",
    "            result.append((state  ,self.fail_prob ,-2.))\n",
    "        return result\n",
    "    def discount(self):\n",
    "        return 1.\n",
    "    def states(self):\n",
    "        return range(1,self.N+1)\n",
    "    \n",
    "    \n",
    "mdp=TransportationMDP(10)\n",
    "print(mdp.actions(3))\n",
    "print(mdp.actions(9))\n",
    "print(mdp.succProbReward(3,'walk'))\n",
    "print(mdp.succProbReward(4,'tram'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db908009",
   "metadata": {},
   "source": [
    "# Policy\n",
    "\n",
    "+ A policy $\\pi : S \\to A$ is a prescription of which possible action to take $A(s)$ in a given state $s \\in S$. Hence, a policy yields/generates a path.\n",
    "\n",
    "### Utility of a Policy\n",
    "\n",
    "+ __The utility of a $\\pi$__ is the discounted sum of the rewards on a path\n",
    "\n",
    "### Value of a Policy\n",
    "\n",
    "+ __The value of a policy__ is the expected utility.\n",
    "\n",
    "$$ V_\\pi = \\mathbb E [U]$$\n",
    "\n",
    "$$ V_\\pi = \\frac{1}{N} \\sum_{i=1} ^N U_i ,$$\n",
    "where $u_i$ denotes the discounted sum of the rewards on $i.$th path yielded by $\\pi$.\n",
    "\n",
    "$$ U_i = R_1 + \\gamma R_2 + \\gamma^2 R_3 $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89acecf",
   "metadata": {},
   "source": [
    "## State-Value functon \n",
    "\n",
    "## $V_\\pi (s) = \\sum_{s'} T(s,\\pi(s),s') \\; [R(s,\\pi(a),s') + \\gamma V_\\pi (s')]$\n",
    "\n",
    "A value of a state under a policy $\\pi$ is the expected utility of following $\\pi$ on a given state $s$ onwards.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed38d72",
   "metadata": {},
   "source": [
    "$$\n",
    "V_\\pi (s) = \\begin{cases}\n",
    "0 & \\text{ if } IsEnd(s)\\\\\n",
    "Q_\\pi (s,a) & \\text{otherwise} \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "where\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b2c3b6",
   "metadata": {},
   "source": [
    "## State-Action-Value functon \n",
    "\n",
    "## $Q_\\pi (s,a) = \\sum_{s'} T(s,a,s') \\; [R(s,a,s') + \\gamma V_\\pi (s')]$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1eb4022",
   "metadata": {},
   "source": [
    "# Policy Evaluation\n",
    "\n",
    "1. $\\forall s \\in S \\; \\text{Initialize value of a state under a policy } V_\\pi ^0 (s)\\leftarrow 0$\n",
    "2. For each iteration $t \\dots t_{end}$\n",
    "3. For each state $s$\n",
    "$$ V_\\pi ^t (s) \\leftarrow \\sum_{s'} T(s,\\pi(s),s') \\; [R(s,\\pi(s),s') + \\gamma V_\\pi ^{t-1} (s')]$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Repeat until $$ \\text{max}_{s \\in S} \\mid V_\\pi ^t (s) - V_\\pi ^{t-1} (s) \\mid \\leq \\epsilon $$\n",
    "\n",
    "### Time Compliexty $O(t_{end} S S')$\n",
    "where\n",
    "1. $t_{end}$ number of iteration\n",
    "2. $S'$ successors ( number of s' with T(s,a,s')>0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843a7be7",
   "metadata": {},
   "source": [
    "# Optimal Value Function\n",
    "\n",
    "\n",
    "### $$\n",
    "V_* (s) = \\begin{cases}\n",
    "0 & \\text{ if } IsEnd(s)\\\\\n",
    "\\text{max}_{a \\in A(s)} Q_* (s,a) & \\text{otherwise} \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "where\n",
    "## $Q_* (s,a) = \\sum_{s'} T(s,a,s') \\; [R(s,a,s') + \\gamma V_* (s')]$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Optimal Policy\n",
    "\n",
    "An optimal policy is a prespecition of selecting best action for in a given state $\\pi_*$\n",
    "\n",
    "### $$ \\pi_* (s) = \\text{argmax}_{a \\in A(s)} Q_* (s,a)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41ce704",
   "metadata": {},
   "source": [
    "# Value Iteration [Bellman 1957]\n",
    "\n",
    "1. $\\forall s \\in S \\; \\text{Initialize value of a state } V_* ^0 (s)\\leftarrow 0$\n",
    "2. For each iteration $t \\dots t_{end}$\n",
    "3. For each state $s$\n",
    "$$ V_* ^t (s) \\leftarrow max_{a \\in A(s)}\\sum_{s'} T(s,a,s') \\; [R(s,a,s') + \\gamma V_* ^{t-1} (s')]$$\n",
    "\n",
    "\n",
    "\n",
    "### Time Compliexty $O(t_{end} S A S')$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecb3ad87",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State \tV(s) \tpi(s)\t at 0.th iteration\n",
      "1\t0.0 \twalk\n",
      "2\t0.0 \twalk\n",
      "3\t0.0 \twalk\n",
      "4\t0.0 \twalk\n",
      "5\t0.0 \twalk\n",
      "6\t0.0 \twalk\n",
      "7\t0.0 \twalk\n",
      "8\t0.0 \twalk\n",
      "9\t0.0 \twalk\n",
      "10\t0.0 \tEnd\n",
      "\n",
      "\n",
      "State \tV(s) \tpi(s)\t at 1.th iteration\n",
      "1\t-1.0 \twalk\n",
      "2\t-1.0 \twalk\n",
      "3\t-1.0 \twalk\n",
      "4\t-1.0 \twalk\n",
      "5\t-1.0 \twalk\n",
      "6\t-1.0 \twalk\n",
      "7\t-1.0 \twalk\n",
      "8\t-1.0 \twalk\n",
      "9\t-1.0 \twalk\n",
      "10\t0.0 \tEnd\n",
      "\n",
      "\n",
      "State \tV(s) \tpi(s)\t at 2.th iteration\n",
      "1\t-2.0 \twalk\n",
      "2\t-2.0 \twalk\n",
      "3\t-2.0 \twalk\n",
      "4\t-2.0 \twalk\n",
      "5\t-2.0 \twalk\n",
      "6\t-2.0 \twalk\n",
      "7\t-2.0 \twalk\n",
      "8\t-2.0 \twalk\n",
      "9\t-1.0 \twalk\n",
      "10\t0.0 \tEnd\n",
      "\n",
      "\n",
      "State \tV(s) \tpi(s)\t at 3.th iteration\n",
      "1\t-3.0 \twalk\n",
      "2\t-3.0 \twalk\n",
      "3\t-3.0 \twalk\n",
      "4\t-3.0 \twalk\n",
      "5\t-3.0 \ttram\n",
      "6\t-3.0 \twalk\n",
      "7\t-3.0 \twalk\n",
      "8\t-2.0 \twalk\n",
      "9\t-1.0 \twalk\n",
      "10\t0.0 \tEnd\n",
      "\n",
      "\n",
      "State \tV(s) \tpi(s)\t at 4.th iteration\n",
      "1\t-4.0 \twalk\n",
      "2\t-4.0 \twalk\n",
      "3\t-4.0 \twalk\n",
      "4\t-4.0 \twalk\n",
      "5\t-3.5 \ttram\n",
      "6\t-4.0 \twalk\n",
      "7\t-3.0 \twalk\n",
      "8\t-2.0 \twalk\n",
      "9\t-1.0 \twalk\n",
      "10\t0.0 \tEnd\n",
      "\n",
      "\n",
      "State \tV(s) \tpi(s)\t at 5.th iteration\n",
      "1\t-5.0 \twalk\n",
      "2\t-5.0 \twalk\n",
      "3\t-5.0 \twalk\n",
      "4\t-4.5 \twalk\n",
      "5\t-3.75 \ttram\n",
      "6\t-4.0 \twalk\n",
      "7\t-3.0 \twalk\n",
      "8\t-2.0 \twalk\n",
      "9\t-1.0 \twalk\n",
      "10\t0.0 \tEnd\n",
      "\n",
      "\n",
      "State \tV(s) \tpi(s)\t at 6.th iteration\n",
      "1\t-6.0 \twalk\n",
      "2\t-6.0 \twalk\n",
      "3\t-5.5 \twalk\n",
      "4\t-4.75 \twalk\n",
      "5\t-3.88 \ttram\n",
      "6\t-4.0 \twalk\n",
      "7\t-3.0 \twalk\n",
      "8\t-2.0 \twalk\n",
      "9\t-1.0 \twalk\n",
      "10\t0.0 \tEnd\n",
      "\n",
      "\n",
      "State \tV(s) \tpi(s)\t at 7.th iteration\n",
      "1\t-7.0 \twalk\n",
      "2\t-6.5 \twalk\n",
      "3\t-5.75 \twalk\n",
      "4\t-4.88 \twalk\n",
      "5\t-3.94 \ttram\n",
      "6\t-4.0 \twalk\n",
      "7\t-3.0 \twalk\n",
      "8\t-2.0 \twalk\n",
      "9\t-1.0 \twalk\n",
      "10\t0.0 \tEnd\n",
      "\n",
      "\n",
      "State \tV(s) \tpi(s)\t at 8.th iteration\n",
      "1\t-7.5 \twalk\n",
      "2\t-6.75 \twalk\n",
      "3\t-5.88 \twalk\n",
      "4\t-4.94 \twalk\n",
      "5\t-3.97 \ttram\n",
      "6\t-4.0 \twalk\n",
      "7\t-3.0 \twalk\n",
      "8\t-2.0 \twalk\n",
      "9\t-1.0 \twalk\n",
      "10\t0.0 \tEnd\n",
      "\n",
      "\n",
      "State \tV(s) \tpi(s)\t at 9.th iteration\n",
      "1\t-7.75 \twalk\n",
      "2\t-6.88 \twalk\n",
      "3\t-5.94 \twalk\n",
      "4\t-4.97 \twalk\n",
      "5\t-3.98 \ttram\n",
      "6\t-4.0 \twalk\n",
      "7\t-3.0 \twalk\n",
      "8\t-2.0 \twalk\n",
      "9\t-1.0 \twalk\n",
      "10\t0.0 \tEnd\n",
      "\n",
      "\n",
      "State \tV(s) \tpi(s)\t at 10.th iteration\n",
      "1\t-7.88 \twalk\n",
      "2\t-6.94 \twalk\n",
      "3\t-5.97 \twalk\n",
      "4\t-4.98 \twalk\n",
      "5\t-3.99 \ttram\n",
      "6\t-4.0 \twalk\n",
      "7\t-3.0 \twalk\n",
      "8\t-2.0 \twalk\n",
      "9\t-1.0 \twalk\n",
      "10\t0.0 \tEnd\n",
      "\n",
      "\n",
      "State \tV(s) \tpi(s)\t at 11.th iteration\n",
      "1\t-7.94 \twalk\n",
      "2\t-6.97 \twalk\n",
      "3\t-5.98 \twalk\n",
      "4\t-4.99 \twalk\n",
      "5\t-4.0 \ttram\n",
      "6\t-4.0 \twalk\n",
      "7\t-3.0 \twalk\n",
      "8\t-2.0 \twalk\n",
      "9\t-1.0 \twalk\n",
      "10\t0.0 \tEnd\n",
      "\n",
      "\n",
      "State \tV(s) \tpi(s)\t at 12.th iteration\n",
      "1\t-7.97 \twalk\n",
      "2\t-6.98 \twalk\n",
      "3\t-5.99 \twalk\n",
      "4\t-5.0 \twalk\n",
      "5\t-4.0 \ttram\n",
      "6\t-4.0 \twalk\n",
      "7\t-3.0 \twalk\n",
      "8\t-2.0 \twalk\n",
      "9\t-1.0 \twalk\n",
      "10\t0.0 \tEnd\n",
      "\n",
      "\n",
      "State \tV(s) \tpi(s)\t at 13.th iteration\n",
      "1\t-7.98 \twalk\n",
      "2\t-6.99 \twalk\n",
      "3\t-6.0 \twalk\n",
      "4\t-5.0 \twalk\n",
      "5\t-4.0 \ttram\n",
      "6\t-4.0 \twalk\n",
      "7\t-3.0 \twalk\n",
      "8\t-2.0 \twalk\n",
      "9\t-1.0 \twalk\n",
      "10\t0.0 \tEnd\n",
      "\n",
      "\n",
      "State \tV(s) \tpi(s)\t at 14.th iteration\n",
      "1\t-7.99 \twalk\n",
      "2\t-7.0 \twalk\n",
      "3\t-6.0 \twalk\n",
      "4\t-5.0 \twalk\n",
      "5\t-4.0 \ttram\n",
      "6\t-4.0 \twalk\n",
      "7\t-3.0 \twalk\n",
      "8\t-2.0 \twalk\n",
      "9\t-1.0 \twalk\n",
      "10\t0.0 \tEnd\n",
      "\n",
      "\n",
      "State \tV(s) \tpi(s)\t at 15.th iteration\n",
      "1\t-8.0 \twalk\n",
      "2\t-7.0 \twalk\n",
      "3\t-6.0 \twalk\n",
      "4\t-5.0 \twalk\n",
      "5\t-4.0 \ttram\n",
      "6\t-4.0 \twalk\n",
      "7\t-3.0 \twalk\n",
      "8\t-2.0 \twalk\n",
      "9\t-1.0 \twalk\n",
      "10\t0.0 \tEnd\n",
      "\n",
      "\n",
      "State \tV(s) \tpi(s)\t at 16.th iteration\n",
      "1\t-8.0 \twalk\n",
      "2\t-7.0 \twalk\n",
      "3\t-6.0 \twalk\n",
      "4\t-5.0 \twalk\n",
      "5\t-4.0 \ttram\n",
      "6\t-4.0 \twalk\n",
      "7\t-3.0 \twalk\n",
      "8\t-2.0 \twalk\n",
      "9\t-1.0 \twalk\n",
      "10\t0.0 \tEnd\n",
      "\n",
      "\n",
      "State \tV(s) \tpi(s)\t at 17.th iteration\n",
      "1\t-8.0 \twalk\n",
      "2\t-7.0 \twalk\n",
      "3\t-6.0 \twalk\n",
      "4\t-5.0 \twalk\n",
      "5\t-4.0 \ttram\n",
      "6\t-4.0 \twalk\n",
      "7\t-3.0 \twalk\n",
      "8\t-2.0 \twalk\n",
      "9\t-1.0 \twalk\n",
      "10\t0.0 \tEnd\n",
      "\n",
      "\n",
      "State \tV(s) \tpi(s)\t at 18.th iteration\n",
      "1\t-8.0 \twalk\n",
      "2\t-7.0 \twalk\n",
      "3\t-6.0 \twalk\n",
      "4\t-5.0 \twalk\n",
      "5\t-4.0 \ttram\n",
      "6\t-4.0 \twalk\n",
      "7\t-3.0 \twalk\n",
      "8\t-2.0 \twalk\n",
      "9\t-1.0 \twalk\n",
      "10\t0.0 \tEnd\n",
      "\n",
      "\n",
      "State \tV(s) \tpi(s)\t at 19.th iteration\n",
      "1\t-8.0 \twalk\n",
      "2\t-7.0 \twalk\n",
      "3\t-6.0 \twalk\n",
      "4\t-5.0 \twalk\n",
      "5\t-4.0 \ttram\n",
      "6\t-4.0 \twalk\n",
      "7\t-3.0 \twalk\n",
      "8\t-2.0 \twalk\n",
      "9\t-1.0 \twalk\n",
      "10\t0.0 \tEnd\n",
      "\n",
      "\n",
      "State \tV(s) \tpi(s)\t at 20.th iteration\n",
      "1\t-8.0 \twalk\n",
      "2\t-7.0 \twalk\n",
      "3\t-6.0 \twalk\n",
      "4\t-5.0 \twalk\n",
      "5\t-4.0 \ttram\n",
      "6\t-4.0 \twalk\n",
      "7\t-3.0 \twalk\n",
      "8\t-2.0 \twalk\n",
      "9\t-1.0 \twalk\n",
      "10\t0.0 \tEnd\n",
      "\n",
      "\n",
      "State \tV(s) \tpi(s)\t at 21.th iteration\n",
      "1\t-8.0 \twalk\n",
      "2\t-7.0 \twalk\n",
      "3\t-6.0 \twalk\n",
      "4\t-5.0 \twalk\n",
      "5\t-4.0 \ttram\n",
      "6\t-4.0 \twalk\n",
      "7\t-3.0 \twalk\n",
      "8\t-2.0 \twalk\n",
      "9\t-1.0 \twalk\n",
      "10\t0.0 \tEnd\n",
      "\n",
      "\n",
      "State \tV(s) \tpi(s)\t at 22.th iteration\n",
      "1\t-8.0 \twalk\n",
      "2\t-7.0 \twalk\n",
      "3\t-6.0 \twalk\n",
      "4\t-5.0 \twalk\n",
      "5\t-4.0 \ttram\n",
      "6\t-4.0 \twalk\n",
      "7\t-3.0 \twalk\n",
      "8\t-2.0 \twalk\n",
      "9\t-1.0 \twalk\n",
      "10\t0.0 \tEnd\n",
      "\n",
      "\n",
      "State \tV(s) \tpi(s)\t at 23.th iteration\n",
      "1\t-8.0 \twalk\n",
      "2\t-7.0 \twalk\n",
      "3\t-6.0 \twalk\n",
      "4\t-5.0 \twalk\n",
      "5\t-4.0 \ttram\n",
      "6\t-4.0 \twalk\n",
      "7\t-3.0 \twalk\n",
      "8\t-2.0 \twalk\n",
      "9\t-1.0 \twalk\n",
      "10\t0.0 \tEnd\n",
      "\n",
      "\n",
      "State \tV(s) \tpi(s)\t at 24.th iteration\n",
      "1\t-8.0 \twalk\n",
      "2\t-7.0 \twalk\n",
      "3\t-6.0 \twalk\n",
      "4\t-5.0 \twalk\n",
      "5\t-4.0 \ttram\n",
      "6\t-4.0 \twalk\n",
      "7\t-3.0 \twalk\n",
      "8\t-2.0 \twalk\n",
      "9\t-1.0 \twalk\n",
      "10\t0.0 \tEnd\n",
      "\n",
      "\n",
      "State \tV(s) \tpi(s)\t at 25.th iteration\n",
      "1\t-8.0 \twalk\n",
      "2\t-7.0 \twalk\n",
      "3\t-6.0 \twalk\n",
      "4\t-5.0 \twalk\n",
      "5\t-4.0 \ttram\n",
      "6\t-4.0 \twalk\n",
      "7\t-3.0 \twalk\n",
      "8\t-2.0 \twalk\n",
      "9\t-1.0 \twalk\n",
      "10\t0.0 \tEnd\n",
      "\n",
      "\n",
      "State \tV(s) \tpi(s)\t at 26.th iteration\n",
      "1\t-8.0 \twalk\n",
      "2\t-7.0 \twalk\n",
      "3\t-6.0 \twalk\n",
      "4\t-5.0 \twalk\n",
      "5\t-4.0 \ttram\n",
      "6\t-4.0 \twalk\n",
      "7\t-3.0 \twalk\n",
      "8\t-2.0 \twalk\n",
      "9\t-1.0 \twalk\n",
      "10\t0.0 \tEnd\n",
      "\n",
      "\n",
      "State \tV(s) \tpi(s)\t at 27.th iteration\n",
      "1\t-8.0 \twalk\n",
      "2\t-7.0 \twalk\n",
      "3\t-6.0 \twalk\n",
      "4\t-5.0 \twalk\n",
      "5\t-4.0 \ttram\n",
      "6\t-4.0 \twalk\n",
      "7\t-3.0 \twalk\n",
      "8\t-2.0 \twalk\n",
      "9\t-1.0 \twalk\n",
      "10\t0.0 \tEnd\n",
      "\n",
      "\n",
      "State \tV(s) \tpi(s)\t at 28.th iteration\n",
      "1\t-8.0 \twalk\n",
      "2\t-7.0 \twalk\n",
      "3\t-6.0 \twalk\n",
      "4\t-5.0 \twalk\n",
      "5\t-4.0 \ttram\n",
      "6\t-4.0 \twalk\n",
      "7\t-3.0 \twalk\n",
      "8\t-2.0 \twalk\n",
      "9\t-1.0 \twalk\n",
      "10\t0.0 \tEnd\n",
      "\n",
      "\n",
      "State \tV(s) \tpi(s)\t at 29.th iteration\n",
      "1\t-8.0 \twalk\n",
      "2\t-7.0 \twalk\n",
      "3\t-6.0 \twalk\n",
      "4\t-5.0 \twalk\n",
      "5\t-4.0 \ttram\n",
      "6\t-4.0 \twalk\n",
      "7\t-3.0 \twalk\n",
      "8\t-2.0 \twalk\n",
      "9\t-1.0 \twalk\n",
      "10\t0.0 \tEnd\n",
      "\n",
      "\n",
      "State \tV(s) \tpi(s)\t at 30.th iteration\n",
      "1\t-8.0 \twalk\n",
      "2\t-7.0 \twalk\n",
      "3\t-6.0 \twalk\n",
      "4\t-5.0 \twalk\n",
      "5\t-4.0 \ttram\n",
      "6\t-4.0 \twalk\n",
      "7\t-3.0 \twalk\n",
      "8\t-2.0 \twalk\n",
      "9\t-1.0 \twalk\n",
      "10\t0.0 \tEnd\n",
      "\n",
      "\n",
      "State \tV(s) \tpi(s)\t at 31.th iteration\n",
      "1\t-8.0 \twalk\n",
      "2\t-7.0 \twalk\n",
      "3\t-6.0 \twalk\n",
      "4\t-5.0 \twalk\n",
      "5\t-4.0 \ttram\n",
      "6\t-4.0 \twalk\n",
      "7\t-3.0 \twalk\n",
      "8\t-2.0 \twalk\n",
      "9\t-1.0 \twalk\n",
      "10\t0.0 \tEnd\n",
      "\n",
      "\n",
      "State \tV(s) \tpi(s)\t at 32.th iteration\n",
      "1\t-8.0 \twalk\n",
      "2\t-7.0 \twalk\n",
      "3\t-6.0 \twalk\n",
      "4\t-5.0 \twalk\n",
      "5\t-4.0 \ttram\n",
      "6\t-4.0 \twalk\n",
      "7\t-3.0 \twalk\n",
      "8\t-2.0 \twalk\n",
      "9\t-1.0 \twalk\n",
      "10\t0.0 \tEnd\n",
      "\n",
      "\n",
      "State \tV(s) \tpi(s)\t at 33.th iteration\n",
      "1\t-8.0 \twalk\n",
      "2\t-7.0 \twalk\n",
      "3\t-6.0 \twalk\n",
      "4\t-5.0 \twalk\n",
      "5\t-4.0 \ttram\n",
      "6\t-4.0 \twalk\n",
      "7\t-3.0 \twalk\n",
      "8\t-2.0 \twalk\n",
      "9\t-1.0 \twalk\n",
      "10\t0.0 \tEnd\n",
      "\n",
      "\n",
      "State \tV(s) \tpi(s)\t at 34.th iteration\n",
      "1\t-8.0 \twalk\n",
      "2\t-7.0 \twalk\n",
      "3\t-6.0 \twalk\n",
      "4\t-5.0 \twalk\n",
      "5\t-4.0 \ttram\n",
      "6\t-4.0 \twalk\n",
      "7\t-3.0 \twalk\n",
      "8\t-2.0 \twalk\n",
      "9\t-1.0 \twalk\n",
      "10\t0.0 \tEnd\n",
      "\n",
      "\n",
      "State \tV(s) \tpi(s)\t at 35.th iteration\n",
      "1\t-8.0 \twalk\n",
      "2\t-7.0 \twalk\n",
      "3\t-6.0 \twalk\n",
      "4\t-5.0 \twalk\n",
      "5\t-4.0 \ttram\n",
      "6\t-4.0 \twalk\n",
      "7\t-3.0 \twalk\n",
      "8\t-2.0 \twalk\n",
      "9\t-1.0 \twalk\n",
      "10\t0.0 \tEnd\n",
      "\n",
      "\n",
      "State \tV(s) \tpi(s)\t at 36.th iteration\n",
      "1\t-8.0 \twalk\n",
      "2\t-7.0 \twalk\n",
      "3\t-6.0 \twalk\n",
      "4\t-5.0 \twalk\n",
      "5\t-4.0 \ttram\n",
      "6\t-4.0 \twalk\n",
      "7\t-3.0 \twalk\n",
      "8\t-2.0 \twalk\n",
      "9\t-1.0 \twalk\n",
      "10\t0.0 \tEnd\n",
      "\n",
      "\n",
      "State \tV(s) \tpi(s)\t at 37.th iteration\n",
      "1\t-8.0 \twalk\n",
      "2\t-7.0 \twalk\n",
      "3\t-6.0 \twalk\n",
      "4\t-5.0 \twalk\n",
      "5\t-4.0 \ttram\n",
      "6\t-4.0 \twalk\n",
      "7\t-3.0 \twalk\n",
      "8\t-2.0 \twalk\n",
      "9\t-1.0 \twalk\n",
      "10\t0.0 \tEnd\n",
      "\n",
      "\n",
      "State \tV(s) \tpi(s)\t at 38.th iteration\n",
      "1\t-8.0 \twalk\n",
      "2\t-7.0 \twalk\n",
      "3\t-6.0 \twalk\n",
      "4\t-5.0 \twalk\n",
      "5\t-4.0 \ttram\n",
      "6\t-4.0 \twalk\n",
      "7\t-3.0 \twalk\n",
      "8\t-2.0 \twalk\n",
      "9\t-1.0 \twalk\n",
      "10\t0.0 \tEnd\n",
      "\n",
      "\n",
      "State \tV(s) \tpi(s)\t at 39.th iteration\n",
      "1\t-8.0 \twalk\n",
      "2\t-7.0 \twalk\n",
      "3\t-6.0 \twalk\n",
      "4\t-5.0 \twalk\n",
      "5\t-4.0 \ttram\n",
      "6\t-4.0 \twalk\n",
      "7\t-3.0 \twalk\n",
      "8\t-2.0 \twalk\n",
      "9\t-1.0 \twalk\n",
      "10\t0.0 \tEnd\n",
      "\n",
      "\n",
      "State \tV(s) \tpi(s)\t at 40.th iteration\n",
      "1\t-8.0 \twalk\n",
      "2\t-7.0 \twalk\n",
      "3\t-6.0 \twalk\n",
      "4\t-5.0 \twalk\n",
      "5\t-4.0 \ttram\n",
      "6\t-4.0 \twalk\n",
      "7\t-3.0 \twalk\n",
      "8\t-2.0 \twalk\n",
      "9\t-1.0 \twalk\n",
      "10\t0.0 \tEnd\n",
      "\n",
      "\n",
      "Conveged!\n"
     ]
    }
   ],
   "source": [
    "def display_params(count,mdp,V,pi):\n",
    "    \n",
    "    print(f'State \\tV(s) \\tpi(s)\\t at {count}.th iteration')\n",
    "    for s in mdp.states():\n",
    "        print(f'{s}\\t{V[s]:.3} \\t{pi[s]}')\n",
    "    print('\\n')\n",
    "\n",
    "def value_iteration(mdp):\n",
    "    V = {s:0. for s in mdp.states()}\n",
    "    def Q(s,a):\n",
    "        return sum( p*(r + (mdp.discount()*V[s_next])) for s_next, p, r in mdp.succProbReward(s,a))    \n",
    "    def pi():\n",
    "        pi={}\n",
    "        for s in mdp.states():\n",
    "            pi[s] = max((Q(s,a),a) for a in mdp.actions(s))[1] if not mdp.isEnd(s) else 'End'\n",
    "        return pi\n",
    "    count=0    \n",
    "    display_params(count,mdp,V,pi())\n",
    "    while True:\n",
    "        Vnew=dict()\n",
    "        for s in mdp.states():\n",
    "            if mdp.isEnd(s):\n",
    "                Vnew[s]=0.\n",
    "            else:\n",
    "                Vnew[s]=max(Q(s,a)for a in mdp.actions(s))\n",
    "        if max(abs(V[state]-Vnew[state]) for state in mdp.states()) < 1e-10:\n",
    "            print('converged!')\n",
    "            break\n",
    "        V=Vnew\n",
    "        count+=1\n",
    "        display_params(count,mdp,V,pi())\n",
    "value_iteration(mdp)        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pDL",
   "language": "python",
   "name": "pdl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
