{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0268540e",
   "metadata": {},
   "source": [
    "## $$ \\textbf{From Temporal Different Learning to Q-learning}$$\n",
    "\n",
    "#### Data: $$ s_0;a_1,r_1, s_1;a_2,r_2, s_3;\\dots, a_n,r_n,s_n$$\n",
    "\n",
    "#### A data point: $$ (s,a,r,s') $$\n",
    "\n",
    "#### Prediction at a single data point: $$ Pred(w) := V(s;w) $$\n",
    "\n",
    "#### True value of a single data point: $$ Target := r + \\gamma V(s',w)$$\n",
    "\n",
    "#### Loss function to compute the loss: $$ min_w \\frac{1}{2} (Pred(w) - Target)^2$$\n",
    "\n",
    "#### The gradient of the loss function w.r.t. $w$:$$ (Pred(w) - Target) \\nabla_w Pred(w)$$\n",
    "\n",
    "\n",
    "#### Gradient Descent Update:\n",
    "$$ w \\leftarrow w - \\eta \\big(Pred(w) - Target \\big) \\nabla_w Pred(w)$$\n",
    "\n",
    "Update the weights $w$ in the negative direction of the gradient of the loss w.r.t. $w$. \n",
    "\n",
    "#### Gradient Descent Update for linear functions: $$ w \\leftarrow w - \\eta \\big(w \\cdot \\phi(s) - (r + \\gamma w \\phi(s') \\big) \\phi(s)$$\n",
    "\n",
    "as \n",
    "$$ V(s;w) = w \\phi(s) $$ \n",
    "$$ \\nabla_w V(s;w) = \\phi(s) $$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5773d080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.th update: Pred:0.000\tTarget:0.500\tGradient:[-0.5 -1. ]\tLoss:0.125\n",
      "1.th update: Pred:1.250\tTarget:1.500\tGradient:[-0.25 -0.5 ]\tLoss:0.031\n",
      "2.th update: Pred:1.875\tTarget:2.000\tGradient:[-0.125 -0.25 ]\tLoss:0.008\n",
      "3.th update: Pred:2.188\tTarget:2.250\tGradient:[-0.0625 -0.125 ]\tLoss:0.002\n",
      "4.th update: Pred:2.344\tTarget:2.375\tGradient:[-0.03125 -0.0625 ]\tLoss:0.000\n",
      "5.th update: Pred:2.422\tTarget:2.438\tGradient:[-0.015625 -0.03125 ]\tLoss:0.000\n",
      "6.th update: Pred:2.461\tTarget:2.469\tGradient:[-0.0078125 -0.015625 ]\tLoss:0.000\n",
      "7.th update: Pred:2.480\tTarget:2.484\tGradient:[-0.00390625 -0.0078125 ]\tLoss:0.000\n",
      "8.th update: Pred:2.490\tTarget:2.492\tGradient:[-0.00195312 -0.00390625]\tLoss:0.000\n",
      "9.th update: Pred:2.495\tTarget:2.496\tGradient:[-0.00097656 -0.00195312]\tLoss:0.000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "eta, gamma, r=.5, 1., .5\n",
    "phi_s = np.array([1., 2.])\n",
    "phi_s_prime = np.array([1., 1.5])\n",
    "w = np.array([0., 0.])\n",
    "for i in range(10):\n",
    "    # (1) Generate predictions\n",
    "    pred = w@phi_s\n",
    "    # (2) Compute target \n",
    "    target = r + gamma * w @  phi_s_prime\n",
    "    # (3) Compute loss\n",
    "    loss = .5*((pred-target)**2)\n",
    "    # (4) Compute gradient\n",
    "    gradient = (pred - target) * phi_s\n",
    "    # (5) Update weights\n",
    "    w -= eta * (pred - target) * phi_s\n",
    "    print(f'{i}.th update: Pred:{pred:.3f}\\tTarget:{target:.3f}\\tGradient:{gradient}\\tLoss:{loss:.3f}')\n",
    "    #print(pred, target, loss, gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7c3dcf",
   "metadata": {},
   "source": [
    "# $$ \\textbf{Q-learning} $$\n",
    "\n",
    "#### Prediction at a single data point: $$ Pred(w) := \\hat Q_* (s, a;w) $$\n",
    "\n",
    "#### True value of a single data point: $$ Target := r + \\gamma max_{a' \\in A(s')} \\hat Q_* (s',a';w)$$\n",
    "\n",
    "\n",
    "#### Gradient Descent Update : $$ w \\leftarrow w - \\eta \\big[ \\hat Q_* (s,a;w) - (r + \\gamma max_{a' \\in A(s') )} \\hat Q_* (s',a',w)\n",
    "\\big] \\nabla_w \\hat Q_* (s,a;w) $$\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pDL",
   "language": "python",
   "name": "pdl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
