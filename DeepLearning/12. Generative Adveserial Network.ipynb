{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "infinite-italic",
   "metadata": {},
   "source": [
    "# Not yet finished. Generative Adveserial Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blond-lexington",
   "metadata": {},
   "source": [
    "### What is a Generative Model ?\n",
    "\n",
    "Given a set of data instances X and a set of labels Y:\n",
    "+ Generative model captures the joint probability p(X,Y)(ergo p(X) if there are no labels).\n",
    "+ Discriminative models capture the conditional probability p(Y|X).\n",
    "\n",
    "\n",
    "![alt text](https://developers.google.com/machine-learning/gan/images/generative_v_discriminative.png \"1\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "accessible-norfolk",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://colab.research.google.com/github/tensorflow/gan/blob/master/tensorflow_gan/examples/colab_notebooks/tfgan_tutorial.ipynb?utm_source=ss-gan&utm_campaign=colab-external&utm_medium=referral&utm_content=tfgan-intro\n",
    "    \n",
    "# https://github.com/tensorflow/gan/tree/master/tensorflow_gan/examples    \n",
    "\n",
    "# Generative Adversarial Networks (GAN) example in PyTorch. Tested with PyTorch 0.4.1, Python 3.6.7 (Nov 2018)\n",
    "# See related blog post at https://medium.com/@devnag/generative-adversarial-networks-gans-in-50-lines-of-code-pytorch-e81b79659e3f#.sch4xgsa9\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "certain-journalism",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data [Only 4 moments]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "# Data params\n",
    "data_mean = 4\n",
    "data_stddev = 1.25\n",
    "\n",
    "# ### Uncomment only one of these to define what data is actually sent to the Discriminator\n",
    "(name, preprocess, d_input_func) = (\"Raw data\", lambda data: data, lambda x: x)\n",
    "(name, preprocess, d_input_func) = (\"Data and variances\", lambda data: decorate_with_diffs(data, 2.0), lambda x: x * 2)\n",
    "(name, preprocess, d_input_func) = (\"Data and diffs\", lambda data: decorate_with_diffs(data, 1.0), lambda x: x * 2)\n",
    "(name, preprocess, d_input_func) = (\"Only 4 moments\", lambda data: get_moments(data), lambda x: 4)\n",
    "print(\"Using data [%s]\" % (name))\n",
    "\n",
    "\n",
    "# ##### DATA: Target data and generator input data\n",
    "\n",
    "def get_distribution_sampler(mu, sigma):\n",
    "    return lambda n: torch.Tensor(np.random.normal(mu, sigma, (1, n)))  # Gaussian\n",
    "\n",
    "def get_generator_input_sampler():\n",
    "    return lambda m, n: torch.rand(m, n)  # Uniform-dist data into generator, _NOT_ Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-theory",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-purple",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "needed-slovakia",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "homeless-colorado",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##### MODELS: Generator model and discriminator model\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, f):\n",
    "        super(Generator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "        self.f = f\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.map1(x)\n",
    "        x = self.f(x)\n",
    "        x = self.map2(x)\n",
    "        x = self.f(x)\n",
    "        x = self.map3(x)\n",
    "        return x\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, f):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "        self.f = f\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.f(self.map1(x))\n",
    "        x = self.f(self.map2(x))\n",
    "        return self.f(self.map3(x))\n",
    "    \n",
    "    \n",
    "def extract(v):\n",
    "    return v.data.storage().tolist()\n",
    "\n",
    "def stats(d):\n",
    "    return [np.mean(d), np.std(d)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_moments(d):\n",
    "    # Return the first 4 moments of the data provided\n",
    "    mean = torch.mean(d)\n",
    "    diffs = d - mean\n",
    "    var = torch.mean(torch.pow(diffs, 2.0))\n",
    "    std = torch.pow(var, 0.5)\n",
    "    zscores = diffs / std\n",
    "    skews = torch.mean(torch.pow(zscores, 3.0))\n",
    "    kurtoses = torch.mean(torch.pow(zscores, 4.0)) - 3.0  # excess kurtosis, should be 0 for Gaussian\n",
    "    final = torch.cat((mean.reshape(1,), std.reshape(1,), skews.reshape(1,), kurtoses.reshape(1,)))\n",
    "    return final\n",
    "\n",
    "def decorate_with_diffs(data, exponent, remove_raw_data=False):\n",
    "    mean = torch.mean(data.data, 1, keepdim=True)\n",
    "    mean_broadcast = torch.mul(torch.ones(data.size()), mean.tolist()[0][0])\n",
    "    diffs = torch.pow(data - Variable(mean_broadcast), exponent)\n",
    "    if remove_raw_data:\n",
    "        return torch.cat([diffs], 1)\n",
    "    else:\n",
    "        return torch.cat([data, diffs], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "based-julian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: D (0.5796899199485779 real_err, 0.8135262727737427 fake_err) G (0.5874426960945129 err); Real Dist ([3.856142955839634, 1.2598316232339977]),  Fake Dist ([0.2578824281692505, 0.04977261993244023]) \n",
      "Plotting the generated distribution...\n",
      " Values: [0.27418190240859985, 0.18437938392162323, 0.30481383204460144, 0.2385162115097046, 0.30528706312179565, 0.22785300016403198, 0.2752673625946045, 0.25673454999923706, 0.3484914302825928, 0.3237861692905426, 0.22758591175079346, 0.23789098858833313, 0.273847758769989, 0.2915406823158264, 0.25253579020500183, 0.3432212769985199, 0.34097620844841003, 0.18416377902030945, 0.2501744031906128, 0.24122552573680878, 0.1966744065284729, 0.18684649467468262, 0.21074345707893372, 0.21641725301742554, 0.22570759057998657, 0.24114209413528442, 0.18642492592334747, 0.2777791917324066, 0.2772972881793976, 0.21125105023384094, 0.19440101087093353, 0.18927758932113647, 0.3485107421875, 0.29451313614845276, 0.3444976508617401, 0.20848943293094635, 0.2723909318447113, 0.1916547566652298, 0.21062618494033813, 0.20303769409656525, 0.23044370114803314, 0.20857423543930054, 0.2726280093193054, 0.24936240911483765, 0.21341097354888916, 0.17976495623588562, 0.21880576014518738, 0.3457920253276825, 0.17933444678783417, 0.2896174490451813, 0.23737560212612152, 0.261385977268219, 0.21945145726203918, 0.323954313993454, 0.32025453448295593, 0.30733585357666016, 0.18870526552200317, 0.3068060874938965, 0.19628852605819702, 0.19449633359909058, 0.28279709815979004, 0.2147374153137207, 0.2548736333847046, 0.3503696918487549, 0.2452847808599472, 0.2678011357784271, 0.33247700333595276, 0.22041656076908112, 0.1978592574596405, 0.263131320476532, 0.2817413806915283, 0.3333967626094818, 0.1964641511440277, 0.20550939440727234, 0.2870672345161438, 0.27332809567451477, 0.2659962773323059, 0.33169323205947876, 0.340987890958786, 0.25487256050109863, 0.23812398314476013, 0.2354554682970047, 0.2921777665615082, 0.29907602071762085, 0.3174933195114136, 0.26021242141723633, 0.34799325466156006, 0.19760163128376007, 0.25482332706451416, 0.32649973034858704, 0.3024921715259552, 0.22342023253440857, 0.1875620186328888, 0.2902756929397583, 0.2120426446199417, 0.2248385101556778, 0.3374330401420593, 0.21181611716747284, 0.2865275740623474, 0.32214832305908203, 0.2469395101070404, 0.22797630727291107, 0.29252004623413086, 0.2655586004257202, 0.28647956252098083, 0.2785398066043854, 0.3237156271934509, 0.24764838814735413, 0.28742074966430664, 0.28775840997695923, 0.19644266366958618, 0.30643430352211, 0.2464442253112793, 0.28416141867637634, 0.2761436402797699, 0.3312501907348633, 0.2634924352169037, 0.18170754611492157, 0.3125438094139099, 0.1810702085494995, 0.20546673238277435, 0.259977251291275, 0.20323127508163452, 0.19301632046699524, 0.2362610399723053, 0.20315201580524445, 0.2542004883289337, 0.2680429518222809, 0.23564638197422028, 0.21910360455513, 0.2209576666355133, 0.22491902112960815, 0.28590643405914307, 0.18682289123535156, 0.2979457974433899, 0.3199360966682434, 0.2706342339515686, 0.19240844249725342, 0.25184500217437744, 0.2927500009536743, 0.21150261163711548, 0.2724103033542633, 0.2746227979660034, 0.1939992606639862, 0.23278500139713287, 0.27376312017440796, 0.20664533972740173, 0.20295961201190948, 0.21252305805683136, 0.3454647958278656, 0.2210179716348648, 0.26331567764282227, 0.2018234133720398, 0.315456748008728, 0.25097736716270447, 0.1923607885837555, 0.18379127979278564, 0.3301926553249359, 0.27758753299713135, 0.3243992328643799, 0.1837228536605835, 0.184758722782135, 0.20896998047828674, 0.20430219173431396, 0.3418552279472351, 0.22929908335208893, 0.29211512207984924, 0.1797579675912857, 0.30763015151023865, 0.18106934428215027, 0.23695291578769684, 0.21581192314624786, 0.216839998960495, 0.24047759175300598, 0.20392805337905884, 0.18053339421749115, 0.33138084411621094, 0.20611804723739624, 0.20313061773777008, 0.2883588373661041, 0.3394373059272766, 0.20050156116485596, 0.18500873446464539, 0.18292076885700226, 0.19303445518016815, 0.23772402107715607, 0.20095546543598175, 0.2748032212257385, 0.27121734619140625, 0.22267159819602966, 0.19659607112407684, 0.3099227249622345, 0.3301374316215515, 0.1957457959651947, 0.21760061383247375, 0.24341510236263275, 0.23079544305801392, 0.24980613589286804, 0.22977979481220245, 0.2305639535188675, 0.18947507441043854, 0.2408227026462555, 0.22352224588394165, 0.27992597222328186, 0.29756346344947815, 0.24387571215629578, 0.28363171219825745, 0.1830356866121292, 0.18493610620498657, 0.2350512146949768, 0.33646056056022644, 0.26704344153404236, 0.2654167711734772, 0.3227907717227936, 0.288444846868515, 0.209649920463562, 0.18484313786029816, 0.328203022480011, 0.30670642852783203, 0.2274782359600067, 0.22615787386894226, 0.2734917104244232, 0.2154855579137802, 0.3031730651855469, 0.22393786907196045, 0.34782853722572327, 0.2607470452785492, 0.24201850593090057, 0.27911263704299927, 0.22692763805389404, 0.18505899608135223, 0.2702183425426483, 0.326395720243454, 0.23308902978897095, 0.206231951713562, 0.24394312500953674, 0.2931814193725586, 0.21448245644569397, 0.3118656277656555, 0.20015141367912292, 0.31785938143730164, 0.3451640009880066, 0.24543516337871552, 0.286176860332489, 0.19547872245311737, 0.250670850276947, 0.20093314349651337, 0.30085456371307373, 0.28881600499153137, 0.22062760591506958, 0.18106381595134735, 0.23570391535758972, 0.3500935733318329, 0.34861859679222107, 0.3429822027683258, 0.282253235578537, 0.19607318937778473, 0.305073618888855, 0.24899885058403015, 0.23988863825798035, 0.21180295944213867, 0.3039868474006653, 0.24685779213905334, 0.26746106147766113, 0.3261607885360718, 0.1849573850631714, 0.205235093832016, 0.2744954824447632, 0.21616390347480774, 0.2035941779613495, 0.2573166489601135, 0.2932087182998657, 0.1878223568201065, 0.24798843264579773, 0.17847193777561188, 0.23567074537277222, 0.19351671636104584, 0.2675425708293915, 0.3542267084121704, 0.2770729064941406, 0.21952053904533386, 0.21490374207496643, 0.2206176519393921, 0.35259875655174255, 0.22726011276245117, 0.2258550226688385, 0.2661360204219818, 0.21485693752765656, 0.2674281597137451, 0.23094896972179413, 0.18210352957248688, 0.2495209127664566, 0.2850499749183655, 0.17855121195316315, 0.19949056208133698, 0.26722708344459534, 0.3176696002483368, 0.3322107791900635, 0.3288574814796448, 0.1941361427307129, 0.22364678978919983, 0.2676060199737549, 0.2691366970539093, 0.23262077569961548, 0.32834628224372864, 0.3460727632045746, 0.25152936577796936, 0.32404226064682007, 0.3247826397418976, 0.19662436842918396, 0.21388784050941467, 0.2082374542951584, 0.18409401178359985, 0.28517255187034607, 0.1960071623325348, 0.19293907284736633, 0.3265135884284973, 0.31865254044532776, 0.22351549565792084, 0.28079789876937866, 0.18009498715400696, 0.2397741824388504, 0.28522056341171265, 0.35529738664627075, 0.3360805809497833, 0.231916606426239, 0.3042938709259033, 0.2571455240249634, 0.25838643312454224, 0.21024194359779358, 0.19459427893161774, 0.33241093158721924, 0.25193995237350464, 0.1943962723016739, 0.2862949073314667, 0.3010798692703247, 0.3044970631599426, 0.2829338014125824, 0.3069109618663788, 0.3136785924434662, 0.18384477496147156, 0.2437429428100586, 0.30126315355300903, 0.28897523880004883, 0.3225233852863312, 0.33467572927474976, 0.18216970562934875, 0.22460658848285675, 0.3080242872238159, 0.21300780773162842, 0.2029339075088501, 0.18527251482009888, 0.2609768211841583, 0.27986207604408264, 0.18811559677124023, 0.191457599401474, 0.28233838081359863, 0.1948663592338562, 0.2668270766735077, 0.3122032880783081, 0.19019708037376404, 0.19995780289173126, 0.3536921739578247, 0.315155953168869, 0.18851259350776672, 0.2509613633155823, 0.31088629364967346, 0.30027782917022705, 0.24177177250385284, 0.3121544420719147, 0.1998099982738495, 0.3081361651420593, 0.24884432554244995, 0.21909575164318085, 0.27091726660728455, 0.27560296654701233, 0.22563916444778442, 0.2170121967792511, 0.3370095491409302, 0.3436092436313629, 0.2927868068218231, 0.21392382681369781, 0.21504592895507812, 0.35493969917297363, 0.32618993520736694, 0.1870686262845993, 0.3182845115661621, 0.29309043288230896, 0.22249159216880798, 0.31054747104644775, 0.22997479140758514, 0.18107520043849945, 0.21005159616470337, 0.2029089778661728, 0.26313647627830505, 0.23552341759204865, 0.2253933697938919, 0.33553826808929443, 0.23032957315444946, 0.23415005207061768, 0.20806674659252167, 0.2014397382736206, 0.30032917857170105, 0.313959538936615, 0.2526549994945526, 0.28743141889572144, 0.3411617577075958, 0.2243075966835022, 0.18928401172161102, 0.3440821170806885, 0.24249783158302307, 0.2452544867992401, 0.22014227509498596, 0.21465788781642914, 0.17880623042583466, 0.3519095480442047, 0.19590531289577484, 0.17862209677696228, 0.2490432858467102, 0.26728516817092896, 0.3443072736263275, 0.2194884717464447, 0.3265771269798279, 0.2701988220214844, 0.35016804933547974, 0.28223082423210144, 0.2458619475364685, 0.2375817447900772, 0.1901555359363556, 0.27616405487060547, 0.2757066786289215, 0.29087936878204346, 0.34224268794059753, 0.2190665304660797, 0.24347464740276337, 0.19543638825416565, 0.22335778176784515, 0.3062717914581299, 0.2700772285461426, 0.18566367030143738, 0.25302985310554504, 0.35137367248535156, 0.33488690853118896, 0.32060882449150085, 0.1828039437532425, 0.2481241524219513, 0.22903357446193695, 0.26292285323143005, 0.3136938214302063, 0.30276578664779663, 0.20261678099632263, 0.34140628576278687, 0.3087112009525299, 0.19231252372264862, 0.2899348735809326, 0.24378126859664917, 0.21796275675296783, 0.26982787251472473, 0.3098054826259613, 0.25129106640815735, 0.18834049999713898, 0.24660548567771912, 0.34673988819122314, 0.2504412829875946, 0.26265326142311096, 0.23007914423942566, 0.2276991605758667, 0.26289013028144836, 0.33403217792510986, 0.315670907497406, 0.27884483337402344, 0.26358935236930847, 0.29451286792755127, 0.2813993990421295, 0.3231368660926819, 0.30236876010894775, 0.2389073669910431, 0.1838826835155487, 0.21387895941734314, 0.26083552837371826, 0.18992242217063904, 0.2473001927137375, 0.22783072292804718, 0.3106737434864044, 0.2896943688392639, 0.33323901891708374, 0.3318983316421509, 0.2605752646923065, 0.2845163643360138, 0.3491482734680176, 0.29669007658958435, 0.21592000126838684, 0.18315741419792175, 0.23148512840270996, 0.18690742552280426, 0.23491063714027405, 0.2609124183654785, 0.18824784457683563, 0.23000530898571014, 0.309418261051178]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def train():\n",
    "    # Model parameters\n",
    "    g_input_size = 1      # Random noise dimension coming into generator, per output vector\n",
    "    g_hidden_size = 5     # Generator complexity\n",
    "    g_output_size = 1     # Size of generated output vector\n",
    "    d_input_size = 500    # Minibatch size - cardinality of distributions\n",
    "    d_hidden_size = 10    # Discriminator complexity\n",
    "    d_output_size = 1     # Single dimension for 'real' vs. 'fake' classification\n",
    "    minibatch_size = d_input_size\n",
    "\n",
    "    d_learning_rate = 1e-3\n",
    "    g_learning_rate = 1e-3\n",
    "    sgd_momentum = 0.9\n",
    "\n",
    "    num_epochs = 1#5000\n",
    "    print_interval = 100\n",
    "    d_steps = 20\n",
    "    g_steps = 20\n",
    "\n",
    "    dfe, dre, ge = 0, 0, 0\n",
    "    d_real_data, d_fake_data, g_fake_data = None, None, None\n",
    "\n",
    "    discriminator_activation_function = torch.sigmoid\n",
    "    generator_activation_function = torch.tanh\n",
    "\n",
    "    d_sampler = get_distribution_sampler(data_mean, data_stddev)\n",
    "    gi_sampler = get_generator_input_sampler()\n",
    "    \n",
    "    # Generator.\n",
    "    G = Generator(input_size=g_input_size,\n",
    "                  hidden_size=g_hidden_size,\n",
    "                  output_size=g_output_size,\n",
    "                  f=generator_activation_function)\n",
    "    # Disc.\n",
    "    D = Discriminator(input_size=d_input_func(d_input_size),\n",
    "                      hidden_size=d_hidden_size,\n",
    "                      output_size=d_output_size,\n",
    "                      f=discriminator_activation_function)\n",
    "    criterion = nn.BCELoss()  \n",
    "    d_optimizer = optim.SGD(D.parameters(), lr=d_learning_rate, momentum=sgd_momentum)\n",
    "    g_optimizer = optim.SGD(G.parameters(), lr=g_learning_rate, momentum=sgd_momentum)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for d_index in range(d_steps):\n",
    "            # 1. Train D on real+fake\n",
    "            D.zero_grad()\n",
    "\n",
    "            #  1A: Train D on real\n",
    "            d_real_data = Variable(d_sampler(d_input_size))\n",
    "            d_real_decision = D(preprocess(d_real_data))\n",
    "            d_real_error = criterion(d_real_decision, Variable(torch.ones(d_real_decision.shape)))  # ones = true\n",
    "            d_real_error.backward() # compute/store gradients, but don't change params\n",
    "            \n",
    "            #  1B: Train D on fake\n",
    "            d_gen_input = Variable(gi_sampler(minibatch_size, g_input_size))\n",
    "            d_fake_data = G(d_gen_input).detach()  # detach to avoid training G on these labels\n",
    "            d_fake_decision = D(preprocess(d_fake_data.t()))\n",
    "            d_fake_error = criterion(d_fake_decision, Variable(torch.zeros(d_fake_decision.shape)))  # zeros = fake\n",
    "            d_fake_error.backward()\n",
    "            d_optimizer.step()     # Only optimizes D's parameters; changes based on stored gradients from backward()\n",
    "\n",
    "            dre, dfe = extract(d_real_error)[0], extract(d_fake_error)[0]\n",
    "\n",
    "        for g_index in range(g_steps):\n",
    "            # 2. Train G on D's response (but DO NOT train D on these labels)\n",
    "            G.zero_grad()\n",
    "\n",
    "            gen_input = Variable(gi_sampler(minibatch_size, g_input_size))\n",
    "            g_fake_data = G(gen_input)\n",
    "            dg_fake_decision = D(preprocess(g_fake_data.t()))\n",
    "            g_error = criterion(dg_fake_decision, Variable(torch.ones([1])))  # Train G to pretend it's genuine\n",
    "\n",
    "            g_error.backward()\n",
    "            g_optimizer.step()  # Only optimizes G's parameters\n",
    "            ge = extract(g_error)[0]\n",
    "\n",
    "        if epoch % print_interval == 0:\n",
    "            print(\"Epoch %s: D (%s real_err, %s fake_err) G (%s err); Real Dist (%s),  Fake Dist (%s) \" %\n",
    "                  (epoch, dre, dfe, ge, stats(extract(d_real_data)), stats(extract(d_fake_data))))\n",
    "\n",
    "    print(\"Plotting the generated distribution...\")\n",
    "    values = extract(g_fake_data)\n",
    "    print(\" Values: %s\" % (str(values)))\n",
    "    plt.hist(values, bins=50)\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Histogram of Generated Distribution')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nominated-protein",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artistic-ministry",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pDL] *",
   "language": "python",
   "name": "conda-env-pDL-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
