{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Convolutions\n",
    "\n",
    "\n",
    "Convolutional neural networks are my favs. In this tutorial, I will show you how to implement forward and bacward pass in convolutions.\n",
    "\n",
    "\n",
    "This tutorial is based on [CS231n Winter 2016: Lecture 6-7: Neural Networks, Convolutional Neural Networks](https://cs231n.github.io/convolutional-networks/), [video](https://www.youtube.com/watch?v=i94OvYb6noo&list=PLkt2uSq6rBVctENoVBg1TpCC7OQi31AlC&index=4).\n",
    "\n",
    "### TL,DR\n",
    "\n",
    "+ Implement forward and backward computation flows of convolutions with numpy.\n",
    "+ Sanity check with pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dim_checker(a,b):\n",
    "    return a.shape==b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv:\n",
    "    def __init__(self,in_channels=1, out_channels=1,kernel_size=(2, 2), stride=1, padding=0):\n",
    "        \n",
    "        self.kernel_h,self.kernel_w=kernel_size\n",
    "        self.weight=np.random.randn(out_channels,\n",
    "                               in_channels,\n",
    "                               self.kernel_h,\n",
    "                               self.kernel_w) /np.sqrt(in_channels/2)\n",
    "        self.bias=np.zeros(out_channels)    \n",
    "\n",
    "        \n",
    "        self.stride=stride\n",
    "        self.padding=padding\n",
    "\n",
    "        # Gradients.\n",
    "        self.dweight, self.dbias=None, None\n",
    "        self.cache=dict()\n",
    "\n",
    "    def set_params(self,weights,bias=None):\n",
    "        self.weight,self.bias=weights, bias\n",
    "        n,d,self.kernel_h,self.kernel_w=self.weight.shape        \n",
    "    \n",
    "    def compute_dim(self,X):\n",
    "        # parameter check\n",
    "        xN, xD, xH, xW = X.shape\n",
    "        wN, wD, wH, wW = self.weight.shape\n",
    "        assert wH == wW\n",
    "        assert (xH - wH) % self.stride == 0\n",
    "        assert (xW - wW) % self.stride == 0\n",
    "        self.cache['X']=X\n",
    "        \n",
    "        zH, zW = (xH - wH) // self.stride + 1, (xW - wW) // self.stride + 1\n",
    "        zD,zN = wN,xN\n",
    "        return np.zeros((zN, zD, zH, zW))\n",
    "    \n",
    "    def get_region(self,hight,width):\n",
    "        h1=hight*self.stride\n",
    "        h2=h1+self.kernel_h\n",
    "        w1=width*self.stride\n",
    "        w2=w1+self.kernel_w\n",
    "        return h1,h2,w1,w2\n",
    "    \n",
    "    def convolve_forward_step(self,X_n):\n",
    "        xD, xH, xW = X_n.shape\n",
    "        hZ=int((xH-self.kernel_h)/self.stride+1)\n",
    "        wZ=int((xW-self.kernel_w)/self.stride+1)\n",
    "        Z = np.zeros((len(self.weight),hZ, wZ))\n",
    "        \n",
    "        for d in range(len(Z)):\n",
    "            for i in range(hZ):\n",
    "                for j in range(wZ):\n",
    "                    h1,h2,w1,w2=self.get_region(i,j)\n",
    "                    x_loc = X_n[:, \n",
    "                              h1: h2,\n",
    "                              w1: w2]\n",
    "                    Z[d,i,j]=np.sum(x_loc*self.weight[d])+ self.bias[d]\n",
    "        return Z\n",
    "    \n",
    "    def forward(self,X):\n",
    "        Z=self.compute_dim(X)\n",
    "        for n in range(len(Z)):\n",
    "            Z[n,:,:,:]=self.convolve_forward_step(X[n])\n",
    "        self.cache['Z']=Z\n",
    "        return Z\n",
    "    \n",
    "    def backward(self,dZ):        \n",
    "        assert dim_checker(dZ,self.cache['Z'])\n",
    "        \n",
    "        dX, self.dweight, self.dbias=np.zeros(self.cache['X'].shape), np.zeros(self.weight.shape),np.zeros(self.bias.shape)\n",
    "        (N, depth, hight, width) = dZ.shape\n",
    "         \n",
    "        for n in range(N):\n",
    "            for h in range(hight):        \n",
    "                for w in range(width):      \n",
    "                    for d in range(depth): # correcponds to d.th kernel\n",
    "                        h1,h2,w1,w2=self.get_region(h,w)\n",
    "                        dX[n,:,h1:h2,w1:w2]+= self.weight[d,:,:,:] * dZ[n, d, h, w]\n",
    "                        self.dweight[d,:,:,:] += self.cache['X'][n, :, h1:h2, w1:w2] * dZ[n, d, h, w]            \n",
    "                        self.dbias[d] +=dZ[n, d, h, w]\n",
    "                    \n",
    "        return dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data and determine the hyperparameters of convolution.\n",
    "xN, xD, xH, xW =3, 3, 4, 4\n",
    "X = np.random.randn(xN, xD, xH, xW)\n",
    "#kernel init\n",
    "nW, k, stride = 3, 2, 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution with forward and backward computaton with Pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "conv = nn.Conv1d(in_channels=xD, out_channels=nW,kernel_size=(k, k), stride=stride)\n",
    "\n",
    "weights=conv.weight.data.detach().numpy()\n",
    "bias=conv.bias.data.detach().numpy()\n",
    "\n",
    "x_torch = torch.from_numpy(X).float() \n",
    "x_torch = Variable(x_torch, requires_grad=True)\n",
    "# Compute Conv\n",
    "res=conv(x_torch)\n",
    "# Sum the res\n",
    "out=res.sum()\n",
    "out.backward() # compute gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0883,  0.8323],\n",
       "          [-0.5934,  0.6978]],\n",
       "\n",
       "         [[-0.2491, -0.4646],\n",
       "          [ 0.1451,  0.3833]],\n",
       "\n",
       "         [[-0.1083, -1.1190],\n",
       "          [ 1.0292,  0.1934]]],\n",
       "\n",
       "\n",
       "        [[[-0.5988, -0.1015],\n",
       "          [-0.9550, -0.1143]],\n",
       "\n",
       "         [[-0.5256,  0.6392],\n",
       "          [-0.3477,  0.3384]],\n",
       "\n",
       "         [[ 0.5915,  0.0048],\n",
       "          [-0.0641,  0.6729]]],\n",
       "\n",
       "\n",
       "        [[[ 0.6175, -0.7181],\n",
       "          [ 0.1579,  0.4720]],\n",
       "\n",
       "         [[-0.5260, -0.8538],\n",
       "          [-0.7747,  0.2885]],\n",
       "\n",
       "         [[-1.3564, -0.3551],\n",
       "          [-1.1209,  0.3674]]]], grad_fn=<MkldnnConvolutionBackward>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output of conv\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution with forward and backward computaton with numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our framework\n",
    "our_conv = Conv(in_channels=xD, out_channels=nW, kernel_size=(k, k), stride=stride)\n",
    "# Use the same weights and bias.\n",
    "our_conv.set_params(weights=weights,\n",
    "                    bias=bias)\n",
    "# Compute Conv\n",
    "Z=our_conv.forward(X)\n",
    "# Compute gradients. Note that gradient of addition is 1.\n",
    "dX=our_conv.backward(np.ones(Z.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.0882748 ,  0.83231789],\n",
       "         [-0.59339344,  0.69775635]],\n",
       "\n",
       "        [[-0.24908992, -0.46456248],\n",
       "         [ 0.1451118 ,  0.38327691]],\n",
       "\n",
       "        [[-0.10827968, -1.11901822],\n",
       "         [ 1.02921658,  0.19340986]]],\n",
       "\n",
       "\n",
       "       [[[-0.59878981, -0.10146911],\n",
       "         [-0.95499542, -0.11428114]],\n",
       "\n",
       "        [[-0.52564307,  0.63918315],\n",
       "         [-0.3477486 ,  0.33841396]],\n",
       "\n",
       "        [[ 0.59146703,  0.00477638],\n",
       "         [-0.06407195,  0.6729271 ]]],\n",
       "\n",
       "\n",
       "       [[[ 0.61746663, -0.71805779],\n",
       "         [ 0.15794283,  0.47199205]],\n",
       "\n",
       "        [[-0.52599765, -0.85378458],\n",
       "         [-0.77470156,  0.2885031 ]],\n",
       "\n",
       "        [[-1.35641148, -0.35514035],\n",
       "         [-1.12085108,  0.36742743]]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(np.allclose(res.data.detach().numpy(),Z,atol=1e6))\n",
    "assert np.all(np.allclose(x_torch.grad.data.detach().numpy(),dX))\n",
    "assert np.all(np.allclose(conv.bias.grad.data.detach().numpy(),our_conv.dbias))\n",
    "assert np.all(np.allclose(conv.weight.grad.data.detach().numpy(),our_conv.dweight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We show how to implement forward and backward computation in convolutions\n",
    "# However, let's take a look at it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from d2l import torch as d2l\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def corr2d(X, K):  #@save\n",
    "    \"\"\"Compute 2D cross-correlation.\"\"\"\n",
    "    h, w = K.shape\n",
    "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 2.],\n",
       "        [0., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[0.0, 1.0, 1.0], \n",
    "                  [0.0, 1.0, 0.0], \n",
    "                  [0.0, 0.0, 0.0]])\n",
    "K = torch.tensor([[1.0, 0.0], \n",
    "                  [1.0, 0.0]])\n",
    "corr2d(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What corr2d(X, K) tells us ?\n",
    "\n",
    "Corr2d draws an image to us by looking at X from the eyes of K."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pDL] *",
   "language": "python",
   "name": "conda-env-pDL-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
