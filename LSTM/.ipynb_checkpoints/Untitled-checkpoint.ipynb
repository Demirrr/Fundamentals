{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef example_0():\\n    # learns to repeat simple sequence from random inputs\\n    np.random.seed(0)\\n\\n    # parameters for input data dimension and lstm cell count\\n    mem_cell_ct = 100\\n    x_dim = 50\\n    lstm_param = LstmParam(mem_cell_ct, x_dim)\\n    lstm_net = LstmNetwork(lstm_param)\\n    y_list = [-0.5, 0.2, 0.1, -0.5]\\n    input_val_arr = [np.random.random(x_dim) for _ in y_list]\\n\\n    for cur_iter in range(100):\\n        print(\"iter\", \"%2s\" % str(cur_iter), end=\": \")\\n        for ind in range(len(y_list)):\\n            lstm_net.x_list_add(input_val_arr[ind])\\n\\n        print(\"y_pred = [\" +\\n              \", \".join([\"% 2.5f\" % lstm_net.lstm_node_list[ind].state.h[0] for ind in range(len(y_list))]) +\\n              \"]\", end=\", \")\\n\\n        loss = lstm_net.y_list_is(y_list, ToyLossLayer)\\n        print(\"loss:\", \"%.3e\" % loss)\\n        lstm_param.apply_diff(lr=0.1)\\n        lstm_net.x_list_clear()\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from lstm import LstmParam, LstmNetwork\n",
    "\n",
    "\n",
    "class ToyLossLayer:\n",
    "    \"\"\"\n",
    "    Computes square loss with first element of hidden layer array.\n",
    "    \"\"\"\n",
    "    @classmethod\n",
    "    def loss(self, pred, label):\n",
    "        return (pred[0] - label) ** 2\n",
    "\n",
    "    @classmethod\n",
    "    def bottom_diff(self, pred, label):\n",
    "        diff = np.zeros_like(pred)\n",
    "        diff[0] = 2 * (pred[0] - label)\n",
    "        return diff\n",
    "\n",
    "\"\"\"\n",
    "def example_0():\n",
    "    # learns to repeat simple sequence from random inputs\n",
    "    np.random.seed(0)\n",
    "\n",
    "    # parameters for input data dimension and lstm cell count\n",
    "    mem_cell_ct = 100\n",
    "    x_dim = 50\n",
    "    lstm_param = LstmParam(mem_cell_ct, x_dim)\n",
    "    lstm_net = LstmNetwork(lstm_param)\n",
    "    y_list = [-0.5, 0.2, 0.1, -0.5]\n",
    "    input_val_arr = [np.random.random(x_dim) for _ in y_list]\n",
    "\n",
    "    for cur_iter in range(100):\n",
    "        print(\"iter\", \"%2s\" % str(cur_iter), end=\": \")\n",
    "        for ind in range(len(y_list)):\n",
    "            lstm_net.x_list_add(input_val_arr[ind])\n",
    "\n",
    "        print(\"y_pred = [\" +\n",
    "              \", \".join([\"% 2.5f\" % lstm_net.lstm_node_list[ind].state.h[0] for ind in range(len(y_list))]) +\n",
    "              \"]\", end=\", \")\n",
    "\n",
    "        loss = lstm_net.y_list_is(y_list, ToyLossLayer)\n",
    "        print(\"loss:\", \"%.3e\" % loss)\n",
    "        lstm_param.apply_diff(lr=0.1)\n",
    "        lstm_net.x_list_clear()\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for input data dimension and lstm cell count\n",
    "mem_cell_ct = 100\n",
    "x_dim = 50\n",
    "lstm_param = LstmParam(mem_cell_ct, x_dim)\n",
    "lstm_net = LstmNetwork(lstm_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_list = [-0.5, 0.2, 0.1, -0.5]\n",
    "input_val_arr = [np.random.random(x_dim) for _ in y_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter  0: y_pred = [ 0.04135,  0.06930,  0.11699,  0.16562], loss: 7.535e-01\n",
      "iter  1: y_pred = [-0.22330, -0.32307, -0.39451, -0.43398], loss: 5.991e-01\n",
      "iter  2: y_pred = [-0.14071, -0.18184, -0.21944, -0.23890], loss: 4.451e-01\n",
      "iter  3: y_pred = [-0.13801, -0.16609, -0.20339, -0.23363], loss: 4.281e-01\n",
      "iter  4: y_pred = [-0.13999, -0.15737, -0.19566, -0.23761], loss: 4.136e-01\n",
      "iter  5: y_pred = [-0.14441, -0.15186, -0.19168, -0.24614], loss: 3.998e-01\n",
      "iter  6: y_pred = [-0.15031, -0.14792, -0.18950, -0.25712], loss: 3.861e-01\n",
      "iter  7: y_pred = [-0.15712, -0.14466, -0.18807, -0.26932], loss: 3.726e-01\n",
      "iter  8: y_pred = [-0.16449, -0.14154, -0.18674, -0.28191], loss: 3.590e-01\n",
      "iter  9: y_pred = [-0.17219, -0.13822, -0.18513, -0.29433], loss: 3.454e-01\n",
      "iter 10: y_pred = [-0.18007, -0.13448, -0.18301, -0.30620], loss: 3.319e-01\n",
      "iter 11: y_pred = [-0.18807, -0.13019, -0.18028, -0.31733], loss: 3.183e-01\n",
      "iter 12: y_pred = [-0.19616, -0.12522, -0.17686, -0.32762], loss: 3.045e-01\n",
      "iter 13: y_pred = [-0.20435, -0.11945, -0.17271, -0.33704], loss: 2.904e-01\n",
      "iter 14: y_pred = [-0.21268, -0.11271, -0.16775, -0.34559], loss: 2.759e-01\n",
      "iter 15: y_pred = [-0.22123, -0.10484, -0.16191, -0.35331], loss: 2.608e-01\n",
      "iter 16: y_pred = [-0.23014, -0.09565, -0.15511, -0.36027], loss: 2.448e-01\n",
      "iter 17: y_pred = [-0.23963, -0.08502, -0.14728, -0.36659], loss: 2.280e-01\n",
      "iter 18: y_pred = [-0.25001, -0.07285, -0.13840, -0.37251], loss: 2.100e-01\n",
      "iter 19: y_pred = [-0.26162, -0.05918, -0.12849, -0.37831], loss: 1.910e-01\n",
      "iter 20: y_pred = [-0.27476, -0.04408, -0.11756, -0.38422], loss: 1.710e-01\n",
      "iter 21: y_pred = [-0.28953, -0.02764, -0.10554, -0.39034], loss: 1.504e-01\n",
      "iter 22: y_pred = [-0.30581, -0.00997, -0.09235, -0.39661], loss: 1.295e-01\n",
      "iter 23: y_pred = [-0.32330,  0.00869, -0.07802, -0.40300], loss: 1.089e-01\n",
      "iter 24: y_pred = [-0.34157,  0.02798, -0.06270, -0.40951], loss: 8.935e-02\n",
      "iter 25: y_pred = [-0.36009,  0.04744, -0.04675, -0.41618], loss: 7.141e-02\n",
      "iter 26: y_pred = [-0.37829,  0.06654, -0.03060, -0.42301], loss: 5.561e-02\n",
      "iter 27: y_pred = [-0.39562,  0.08479, -0.01478, -0.42995], loss: 4.225e-02\n",
      "iter 28: y_pred = [-0.41166,  0.10176,  0.00024, -0.43691], loss: 3.139e-02\n",
      "iter 29: y_pred = [-0.42611,  0.11715,  0.01410, -0.44373], loss: 2.287e-02\n",
      "iter 30: y_pred = [-0.43883,  0.13082,  0.02657, -0.45027], loss: 1.639e-02\n",
      "iter 31: y_pred = [-0.44981,  0.14274,  0.03758, -0.45635], loss: 1.160e-02\n",
      "iter 32: y_pred = [-0.45916,  0.15296,  0.04708, -0.46198], loss: 8.127e-03\n",
      "iter 33: y_pred = [-0.46696,  0.16166,  0.05530, -0.46694], loss: 5.653e-03\n",
      "iter 34: y_pred = [-0.47355,  0.16888,  0.06210, -0.47157], loss: 3.913e-03\n",
      "iter 35: y_pred = [-0.47872,  0.17509,  0.06823, -0.47511], loss: 2.702e-03\n",
      "iter 36: y_pred = [-0.48353,  0.17977,  0.07246, -0.47935], loss: 1.866e-03\n",
      "iter 37: y_pred = [-0.48612,  0.18464,  0.07810, -0.48040], loss: 1.292e-03\n",
      "iter 38: y_pred = [-0.49120,  0.18633,  0.07802, -0.48719], loss: 9.116e-04\n",
      "iter 39: y_pred = [-0.48854,  0.19289,  0.08884, -0.47973], loss: 7.172e-04\n",
      "iter 40: y_pred = [-0.50158,  0.18640,  0.07306, -0.50327], loss: 9.240e-04\n",
      "iter 41: y_pred = [-0.47740,  0.20751,  0.11569, -0.45574], loss: 2.772e-03\n",
      "iter 42: y_pred = [-0.53443,  0.16304,  0.02241, -0.56649], loss: 1.299e-02\n",
      "iter 43: y_pred = [-0.40264,  0.25608,  0.21861, -0.32300], loss: 5.802e-02\n",
      "iter 44: y_pred = [-0.63680,  0.00234, -0.24087, -0.79711], loss: 2.623e-01\n",
      "iter 45: y_pred = [-0.24876,  0.29151,  0.28840, -0.17249], loss: 2.142e-01\n",
      "iter 46: y_pred = [-0.61898, -0.05992, -0.29588, -0.75803], loss: 3.050e-01\n",
      "iter 47: y_pred = [-0.47315,  0.13786, -0.03491, -0.51522], loss: 2.301e-02\n",
      "iter 48: y_pred = [-0.44997,  0.16478,  0.02070, -0.47788], loss: 1.052e-02\n",
      "iter 49: y_pred = [-0.45272,  0.17753,  0.04068, -0.47489], loss: 6.890e-03\n",
      "iter 50: y_pred = [-0.46035,  0.18577,  0.05125, -0.47877], loss: 4.602e-03\n",
      "iter 51: y_pred = [-0.46722,  0.19204,  0.05950, -0.48241], loss: 3.088e-03\n",
      "iter 52: y_pred = [-0.47302,  0.19682,  0.06618, -0.48541], loss: 2.094e-03\n",
      "iter 53: y_pred = [-0.47787,  0.20040,  0.07158, -0.48785], loss: 1.445e-03\n",
      "iter 54: y_pred = [-0.48188,  0.20304,  0.07595, -0.48981], loss: 1.020e-03\n",
      "iter 55: y_pred = [-0.48518,  0.20492,  0.07948, -0.49138], loss: 7.392e-04\n",
      "iter 56: y_pred = [-0.48788,  0.20623,  0.08235, -0.49264], loss: 5.515e-04\n",
      "iter 57: y_pred = [-0.49010,  0.20710,  0.08468, -0.49363], loss: 4.236e-04\n",
      "iter 58: y_pred = [-0.49191,  0.20763,  0.08660, -0.49443], loss: 3.344e-04\n",
      "iter 59: y_pred = [-0.49340,  0.20791,  0.08818, -0.49505], loss: 2.705e-04\n",
      "iter 60: y_pred = [-0.49461,  0.20801,  0.08948, -0.49556], loss: 2.235e-04\n",
      "iter 61: y_pred = [-0.49561,  0.20796,  0.09058, -0.49596], loss: 1.877e-04\n",
      "iter 62: y_pred = [-0.49644,  0.20782,  0.09150, -0.49628], loss: 1.599e-04\n",
      "iter 63: y_pred = [-0.49712,  0.20761,  0.09228, -0.49654], loss: 1.376e-04\n",
      "iter 64: y_pred = [-0.49768,  0.20734,  0.09296, -0.49676], loss: 1.194e-04\n",
      "iter 65: y_pred = [-0.49815,  0.20705,  0.09354, -0.49694], loss: 1.043e-04\n",
      "iter 66: y_pred = [-0.49853,  0.20675,  0.09404, -0.49710], loss: 9.153e-05\n",
      "iter 67: y_pred = [-0.49886,  0.20643,  0.09449, -0.49723], loss: 8.065e-05\n",
      "iter 68: y_pred = [-0.49913,  0.20611,  0.09488, -0.49735], loss: 7.128e-05\n",
      "iter 69: y_pred = [-0.49935,  0.20580,  0.09524, -0.49746], loss: 6.317e-05\n",
      "iter 70: y_pred = [-0.49954,  0.20549,  0.09555, -0.49756], loss: 5.610e-05\n",
      "iter 71: y_pred = [-0.49970,  0.20520,  0.09584, -0.49765], loss: 4.992e-05\n",
      "iter 72: y_pred = [-0.49983,  0.20491,  0.09610, -0.49773], loss: 4.448e-05\n",
      "iter 73: y_pred = [-0.49995,  0.20464,  0.09634, -0.49781], loss: 3.970e-05\n",
      "iter 74: y_pred = [-0.50004,  0.20438,  0.09656, -0.49789], loss: 3.547e-05\n",
      "iter 75: y_pred = [-0.50012,  0.20413,  0.09676, -0.49796], loss: 3.173e-05\n",
      "iter 76: y_pred = [-0.50018,  0.20390,  0.09695, -0.49804], loss: 2.841e-05\n",
      "iter 77: y_pred = [-0.50023,  0.20368,  0.09712, -0.49810], loss: 2.546e-05\n",
      "iter 78: y_pred = [-0.50028,  0.20347,  0.09728, -0.49817], loss: 2.284e-05\n",
      "iter 79: y_pred = [-0.50031,  0.20327,  0.09743, -0.49824], loss: 2.051e-05\n",
      "iter 80: y_pred = [-0.50034,  0.20309,  0.09758, -0.49830], loss: 1.842e-05\n",
      "iter 81: y_pred = [-0.50037,  0.20292,  0.09771, -0.49837], loss: 1.656e-05\n",
      "iter 82: y_pred = [-0.50038,  0.20275,  0.09783, -0.49843], loss: 1.490e-05\n",
      "iter 83: y_pred = [-0.50040,  0.20260,  0.09795, -0.49849], loss: 1.341e-05\n",
      "iter 84: y_pred = [-0.50041,  0.20245,  0.09806, -0.49854], loss: 1.207e-05\n",
      "iter 85: y_pred = [-0.50041,  0.20232,  0.09816, -0.49860], loss: 1.088e-05\n",
      "iter 86: y_pred = [-0.50042,  0.20219,  0.09826, -0.49865], loss: 9.804e-06\n",
      "iter 87: y_pred = [-0.50042,  0.20207,  0.09835, -0.49871], loss: 8.840e-06\n",
      "iter 88: y_pred = [-0.50041,  0.20195,  0.09844, -0.49876], loss: 7.974e-06\n",
      "iter 89: y_pred = [-0.50041,  0.20185,  0.09852, -0.49881], loss: 7.195e-06\n",
      "iter 90: y_pred = [-0.50041,  0.20174,  0.09859, -0.49886], loss: 6.495e-06\n",
      "iter 91: y_pred = [-0.50040,  0.20165,  0.09867, -0.49890], loss: 5.864e-06\n",
      "iter 92: y_pred = [-0.50040,  0.20156,  0.09873, -0.49895], loss: 5.296e-06\n",
      "iter 93: y_pred = [-0.50039,  0.20148,  0.09880, -0.49899], loss: 4.784e-06\n",
      "iter 94: y_pred = [-0.50038,  0.20140,  0.09886, -0.49904], loss: 4.323e-06\n",
      "iter 95: y_pred = [-0.50037,  0.20132,  0.09892, -0.49908], loss: 3.907e-06\n",
      "iter 96: y_pred = [-0.50036,  0.20125,  0.09897, -0.49912], loss: 3.531e-06\n",
      "iter 97: y_pred = [-0.50035,  0.20119,  0.09903, -0.49915], loss: 3.193e-06\n",
      "iter 98: y_pred = [-0.50034,  0.20112,  0.09908, -0.49919], loss: 2.887e-06\n",
      "iter 99: y_pred = [-0.50033,  0.20106,  0.09912, -0.49923], loss: 2.611e-06\n"
     ]
    }
   ],
   "source": [
    "for cur_iter in range(100):\n",
    "    print(\"iter\", \"%2s\" % str(cur_iter), end=\": \")\n",
    "    for ind in range(len(y_list)):\n",
    "        lstm_net.x_list_add(input_val_arr[ind])\n",
    "\n",
    "    print(\"y_pred = [\" +\n",
    "          \", \".join([\"% 2.5f\" % lstm_net.lstm_node_list[ind].state.h[0] for ind in range(len(y_list))]) +\n",
    "          \"]\", end=\", \")\n",
    "\n",
    "    loss = lstm_net.y_list_is(y_list, ToyLossLayer)\n",
    "    print(\"loss:\", \"%.3e\" % loss)\n",
    "    lstm_param.apply_diff(lr=0.1)\n",
    "    lstm_net.x_list_clear()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pl2vec)",
   "language": "python",
   "name": "pl2vec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
