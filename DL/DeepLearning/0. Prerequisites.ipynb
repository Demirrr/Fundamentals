{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derivative of a function\n",
    "\n",
    "Let $f$ be a function of $f:\\mathbb{R}^n \\mapsto \\mathbb{R}^m$. The derivative/slope of $f$ on $x$ corresponds the rate of change of $f$ with respect to $x$ and defined as :\n",
    "\n",
    "$$ \\frac{d f(x)}{dx} = \\lim_{h \\to 0} \\frac{f(x+h) - f(x)}{h}$$\n",
    "\n",
    "For example, the derivative of the position of a moving object with respect to time is the object's velocity: this measures how quickly the position of the object changes when time advances. Let $x$ be time in seconds and $f$ is a function indicating the position of the ball in the direction of the right. \n",
    "\n",
    "\n",
    "* The $f_1(x)$ does not change depending on the input $x$. Consequently, an infinitesimal change on $x+h$ does not have any effect on the rate of change in $f_1$,i.e.,$f_1(x)=f_1(x+h)$. In otherwords, **the ball does not move in any direction**.\n",
    "\n",
    "* The $f_2(x)$ changes depending on $x$. An infinitesimal change $x+h$ corresponds to an infinitesimal change on $f_2$,i.e.\n",
    "$(f_2(x+h)-f_2(x))/h=1$. Consequently, the rate of change is **1**. otherwords, **the ball is moving in the direction of the right with a constant velocity.** I\n",
    "\n",
    "* The output of $f_3$ changes depending on $x$. An infinitesimal change $x+h$ corresponds to an infinitesimal change on $f_2$,i.e.\n",
    "$(f_2(x+h)-f_2(x))/h=-1$. Consequently, the rate of change is **-1**. In otherwords, **the ball moving with a constant velocity in the direction of the left**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_1= lambda x: 0 # Gradient is always 0.\n",
    "f_2= lambda x: x # Gradient is always close to 1.\n",
    "f_3= lambda x: -x # Gradient is always close to -1.\n",
    "\n",
    "f_4= lambda x: x**2 # Gradient increases as the input increases\n",
    "f_5= lambda x: -x**2 # Gradient increases as the input increases\n",
    "f_6= lambda x: np.sqrt(x**2).sum() \n",
    "f_7= lambda x: x.sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_derivative(f,x):\n",
    "    h=.00001\n",
    "    return (f(x+h)-f(x))/h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########f_1(x)=0##########\n",
      "f( 1.0 )=0\t df at x is 0.0\n",
      "f( 1.5 )=0\t df at x is 0.0\n",
      "f( 2.0 )=0\t df at x is 0.0\n",
      "f( 5.0 )=0\t df at x is 0.0\n",
      "f( 10.0 )=0\t df at x is 0.0\n",
      "#########f_2(x)=x##########\n",
      "f( 1.0 )=1.0\t df at x is 1.0000000000065512\n",
      "f( 1.5 )=1.5\t df at x is 1.0000000000065512\n",
      "f( 2.0 )=2.0\t df at x is 1.0000000000065512\n",
      "f( 5.0 )=5.0\t df at x is 0.9999999999621422\n",
      "f( 10.0 )=10.0\t df at x is 0.9999999999621422\n",
      "#########f_3(x)=-x##########\n",
      "f( 1.0 )=-1.0\t df at x is -1.0000000000065512\n",
      "f( 1.5 )=-1.5\t df at x is -1.0000000000065512\n",
      "f( 2.0 )=-2.0\t df at x is -1.0000000000065512\n",
      "f( 5.0 )=-5.0\t df at x is -0.9999999999621422\n",
      "f( 10.0 )=-10.0\t df at x is -0.9999999999621422\n",
      "#########f_4(x)=x**2##########\n",
      "f( 1.0 )=1.0\t df at x is 2.00001000001393\n",
      "f( 1.5 )=2.25\t df at x is 3.0000100000204806\n",
      "f( 2.0 )=4.0\t df at x is 4.000010000027032\n",
      "f( 5.0 )=25.0\t df at x is 10.000009999444615\n",
      "f( 10.0 )=100.0\t df at x is 20.00000999942131\n",
      "#########f_5(x)=x**-2##########\n",
      "f( 1.0 )=-1.0\t df at x is -2.00001000001393\n",
      "f( 1.5 )=-2.25\t df at x is -3.0000100000204806\n",
      "f( 2.0 )=-4.0\t df at x is -4.000010000027032\n",
      "f( 5.0 )=-25.0\t df at x is -10.000009999444615\n",
      "f( 10.0 )=-100.0\t df at x is -20.00000999942131\n"
     ]
    }
   ],
   "source": [
    "# Gradients always fixed in f_1 to f_3Let's calculate derivatives of 3 different function\n",
    "print('#########f_1(x)=0##########')\n",
    "for x in [1.0, 1.5, 2.0 ,5.0, 10.0]:\n",
    "    print('f( {0} )={1}\\t df at x is {2}'.format(x,f_1(x),calculate_derivative(f_1,x)))\n",
    "    \n",
    "print('#########f_2(x)=x##########')\n",
    "for x in [1.0, 1.5, 2.0 ,5.0, 10.0]:\n",
    "    print('f( {0} )={1}\\t df at x is {2}'.format(x,f_2(x),calculate_derivative(f_2,x)))\n",
    "    \n",
    "print('#########f_3(x)=-x##########')\n",
    "for x in [1.0, 1.5, 2.0 ,5.0, 10.0]:\n",
    "    print('f( {0} )={1}\\t df at x is {2}'.format(x,f_3(x),calculate_derivative(f_3,x)))\n",
    "    \n",
    "print('#########f_4(x)=x**2##########')\n",
    "for x in [1.0, 1.5, 2.0 ,5.0, 10.0]:\n",
    "    print('f( {0} )={1}\\t df at x is {2}'.format(x,f_4(x),calculate_derivative(f_4,x)))\n",
    "    \n",
    "print('#########f_5(x)=x**-2##########')\n",
    "for x in [1.0, 1.5, 2.0 ,5.0, 10.0]:\n",
    "    print('f( {0} )={1}\\t df at x is {2}'.format(x,f_5(x),calculate_derivative(f_5,x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The output of $f_4$ changes depending on $x$. Increasing $x$ increases the output of $f_3$ **significantly **. The rate of change is positively follows the the $x$. In otherwords, **the ball moving with an increasing velocity in the direction of the right**.\n",
    "\n",
    "\n",
    "* The output of $f_5$ changes depending on $x$. Increasing $x$ decreases the output of $f_3$ **significantly **. The rate of change is negatively follows the behaviour of the $x$. In otherwords, **the ball moving with an increasing velocity in the direction of the left**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analytical and Numerical Gradient\n",
    "\n",
    "Up until now, We use $f:\\mathbb{R}^n \\mapsto \\mathbb{R}^m$ where $n=1$ and $m=1$ and we **numerically calculate** the the derivative of $f$. Such numerical calculation becomes **very slow** as the $n$ increases as shown in the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_partial_derivatives(f,x):\n",
    "    \"\"\"\n",
    "    x is a numpy array (K,)\n",
    "    f is a function that takes x as input and generates R.\n",
    "    \"\"\"\n",
    "    fx = f(x) # evaluate function value at original point\n",
    "    grad = np.zeros(len(x))\n",
    "    h = 0.00001\n",
    "\n",
    "    for ith, val in enumerate(x):\n",
    "        x[ith]+=h # increment by h\n",
    "        fxh = f(x) # evalute f(x + h)\n",
    "        # compute the partial derivative\n",
    "        grad[ith]= (fxh - fx) / h # the slope\n",
    "        x[ith]=val    \n",
    "    return grad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (conex)",
   "language": "python",
   "name": "conex"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
