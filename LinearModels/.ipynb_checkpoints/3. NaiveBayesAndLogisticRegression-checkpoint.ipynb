{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c914bbd0",
   "metadata": {},
   "source": [
    "# Naive Bayes is Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b1e914",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "$\\mathcal D = \\{(x_i,y_i) \\}_{i=1} ^n s.t. \\mathcal D \\sim_{i.i.d} \\mathbb P(\\mathcal X , \\mathcal Y)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adbcf24",
   "metadata": {},
   "source": [
    "#### Naive Bayes with Continues Features\n",
    "\n",
    "\n",
    "$$ \\mathbb p \\left(y|x\\right) = \\frac{\\prod^{d}_{\\alpha=1} \\mathbb p \\left( x_\\alpha | y\\right) \\mathbb p \\left(y\\right)}{ \\mathbb p \\left(x\\right)}$$\n",
    "with:\n",
    "$$ \\mathbb p (x_\\alpha | y ) = \\mathcal{N} (\\mu_{y,\\alpha}, \\sigma_\\alpha)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31c27c7",
   "metadata": {},
   "source": [
    "## Show that Naive Bayes is equivalent of Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbcaf38",
   "metadata": {},
   "source": [
    "\n",
    "### 1 $$ \\mathbb p (y =1 |x) = \\frac{\\prod^{d}_{\\alpha=1} \\mathbb p ( x_\\alpha | y=1) \\mathbb p (y=1)}{ \\mathbb p (x)}$$\n",
    "\n",
    "### 2 $$ \\mathbb p (y =1 |x) = \\frac{\\prod^{d}_{\\alpha=1} \\mathbb p ( x_\\alpha | y=1) \\mathbb p (y=1)}{ \\prod^{d}_{\\alpha=1} \\mathbb p ( x_\\alpha | y=1) \\mathbb p (y=1) + \\prod^{d}_{\\alpha=1} \\mathbb p ( x_\\alpha | y=0) \\mathbb p (y=0)}$$\n",
    "\n",
    "\n",
    "## 3 $$ \\mathbb p (y =1 |x) = \\frac{1}{1 + \\frac{\\prod^{d}_{\\alpha=1} \\mathbb p ( x_\\alpha | y=0) \\mathbb p (y=0)}{\\prod^{d}_{\\alpha=1} \\mathbb p ( x_\\alpha | y=1) \\mathbb p (y=1)}}$$\n",
    "\n",
    "Becase  $\\frac{A}{A+B} = \\frac{1}{1 + \\frac{B}{A}}$\n",
    "\n",
    "\n",
    "### 4 $$ \\mathbb p (y =1 |x) = \\frac{1}{1 + exp\\Big(log\\big( \\frac{\\prod^{d}_{\\alpha=1} \\mathbb p ( x_\\alpha | y=0) \\mathbb p (y=0)}{\\prod^{d}_{\\alpha=1} \\mathbb p ( x_\\alpha | y=1) \\mathbb p (y=1)}\\big)\\Big)}$$\n",
    "\n",
    "Becase exp(ln(x))=x Becase $log(x^1)=-1 log(x)$ and $log(\\frac{a}{b})=-1 log(\\frac{b}{a})$. Hence, we flipped the second term in the denominoator and put a negative sign. In the next step, let us expand this term.\n",
    "\n",
    "\n",
    "### 5 $$ -log \\mathbb p (y=1) + log\\mathbb p (y=0) - log\\prod^{d}_{\\alpha=1} \\mathbb p ( x_\\alpha | y=1)+ log \\prod^{d}_{\\alpha=1} \\mathbb p ( x_\\alpha | y=0) $$\n",
    "Distribute log\n",
    "\n",
    "### 6 $$log \\Big( \\frac{\\mathbb p (y=0)}{\\mathbb p (y=1)} \\Big) + \\sum^{d}_{\\alpha=1} log\\big( \\frac{\\mathbb p ( x_\\alpha | y=0)}{\\mathbb p ( x_\\alpha | y=1)} \\big)$$\n",
    "\n",
    "### 7 $$ \\mathbb p (y =1 |x) = \\frac{1}{1 + exp\\Big(log \\Big( \\frac{\\mathbb p (y=0)}{\\mathbb p (y=1)} \\Big) + \\sum^{d}_{\\alpha=1} log\\big( \\frac{\\mathbb p ( x_\\alpha | y=0)}{\\mathbb p ( x_\\alpha | y=1)} \\big)\\Big)}  $$\n",
    "\n",
    "\n",
    "Group terms. \n",
    "\n",
    "### 8 $$ \\sum^{d}_{\\alpha=1} log\\Big( \\frac{\\frac{\\exp\\big( -\\frac{\\big(x_\\alpha-\\mu_{0,\\alpha }\\big)^2}{2\\sigma^2}\\big)}{\\sqrt{2\\pi \\sigma^2}}}{\\frac{\\exp\\big( -\\frac{\\big(x_\\alpha-\\mu_{1,\\alpha }\\big)^2}{2\\sigma^2}\\big)}{\\sqrt{2\\pi \\sigma^2}}} \\Big) $$\n",
    "Plug in model assumption into the second term.\n",
    "\n",
    "\n",
    "### 9 $$ \\sum^{d}_{\\alpha=1} log\\Big(exp\\Big( \\frac{(x_\\alpha-\\mu_{1,\\alpha }\\big)^2 -(x_\\alpha-\\mu_{0,\\alpha }\\big)^2 }{2 \\sigma^2}\\Big)\\Big) $$\n",
    "$\\sqrt{2\\pi \\sigma^2}$ in the denominators are canceled out. Note that $ \\frac{exp(a)}{exp(b)} = exp(a-b)$.\n",
    "\n",
    "\n",
    "### 10 $$ \\sum^{d}_{\\alpha=1} \\frac{(x_\\alpha-\\mu_{1,\\alpha }\\big)^2 -(x_\\alpha-\\mu_{0,\\alpha }\\big)^2 }{2 \\sigma_\\alpha ^2} $$\n",
    "log(exp(x))=x\n",
    "\n",
    "\n",
    "### 11 $$\\sum^{d}_{\\alpha=1} \\frac{(\\mu_{0,\\alpha } - \\mu_{1,\\alpha }) x_\\alpha } {\\sigma_\\alpha^2 } + \\frac{\\mu_{1,\\alpha}^2-\\mu_{0,\\alpha}^2}{2 \\sigma_\\alpha ^2}$$\n",
    "Completing the square\n",
    "\n",
    "\n",
    "### 12 $$ \\mathbb p (y =1 |x) = \\frac{1}{1 + exp\\Big( log\\frac{1-P}{P} + \\sum^{d}_{\\alpha=1} \\frac{(\\mu_{0,\\alpha } - \\mu_{1,\\alpha }) x_\\alpha } {\\sigma_\\alpha^2 } + \\frac{\\mu_{1,\\alpha}^2-\\mu_{0,\\alpha}^2}{2 \\sigma_\\alpha ^2}\\Big)}$$\n",
    "\n",
    "$P=\\mathbb p (y =0)$ and $1-P=\\mathbb p (y=1)$\n",
    "\n",
    "\n",
    "\n",
    "### 13 $$ \\mathbb p (y =1 |x) = \\frac{1}{1 + exp\\Big( b + w^T x \\Big)}$$\n",
    "\n",
    "where \n",
    "\n",
    "$$ b = log\\frac{1-P}{P} + \\sum^{d}_{\\alpha=1} + \\frac{\\mu_{1,\\alpha}^2-\\mu_{0,\\alpha}^2}{2 \\sigma_\\alpha ^2}$$\n",
    "\n",
    "$$ w = \\sum^{d}_{\\alpha=1} \\frac{(\\mu_{0,\\alpha } - \\mu_{1,\\alpha }) x_\\alpha } {\\sigma_\\alpha^2 }$$\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pDL",
   "language": "python",
   "name": "pdl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
